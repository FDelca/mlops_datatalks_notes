{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b67586b7",
   "metadata": {},
   "source": [
    "# 0 - Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e45258",
   "metadata": {},
   "source": [
    "In this tutorial we will create a model with the following `mlflow setup`:\n",
    "- Tracking server: remote server (EC2)\n",
    "- Backend store: postgresql database\n",
    "- Artifacts store: s3 bucket\n",
    "\n",
    "[Tutorial Link](https://www.youtube.com/watch?v=1ykg4YmbFVA&list=PL3MmuxUbc_hIUISrluw_A7wDSmfOhErJK&index=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004f5814",
   "metadata": {},
   "source": [
    "## 1. Create Cloud Infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dee44c2",
   "metadata": {},
   "source": [
    "### 1.1. Create a `IAM` user in AWS\n",
    "\n",
    "- Provides fine-grained access control across all of AWS. One can specify who can access which services and resources, and under which conditions. Also, with IAM policies, you manage permissions to your workforce and systems to ensure least-privilege permissions.\n",
    "\n",
    "- [Tutorial](https://mlbookcamp.com/article/aws) on how to create one\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024e3aaa",
   "metadata": {},
   "source": [
    "### 1.2. EC2 Instance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba337ff",
   "metadata": {},
   "source": [
    "-  [Tutorial](https://www.youtube.com/watch?v=1ykg4YmbFVA&list=PL3MmuxUbc_hIUISrluw_A7wDSmfOhErJK&index=16)\n",
    "- Amazon Elastic Cloud Compute (EC2) - virtual server for running applications on the AWS infrastructure - [further explanation](https://www.techtarget.com/searchaws/definition/Amazon-EC2-instances)\n",
    "\n",
    "Configurations:\n",
    "- Name: `mlflow-track-server`;\n",
    "- OSImage: `Amazon Linux 2 - Kernel 5.10 SSD` (free tier);\n",
    "- Architecture: `64-bit`\n",
    "- Instance type: `t2.micro` (free tier)\n",
    "- Create a key-pair: (required because we need it to connect via ssh)\n",
    "    - Name: `mlflow-key-pair`\n",
    "    - Save the `.pem` file\n",
    "- Default values\n",
    "- Launch the instance\n",
    "\n",
    "Security Configurations:\n",
    "- Go to security groups of the instance created;\n",
    "- Security group: `launch-wizard-1` (Important to select the same for the \n",
    "- Add a new rule in inbound rules to allow http connection;\n",
    "- Custom TCP - Port:`5000` - Anywhere/MyIP\n",
    "- Save Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41705245",
   "metadata": {},
   "source": [
    "### 1.3. Create a S3 bucket - location `Ireland`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60bcd0e6",
   "metadata": {},
   "source": [
    "- Bucket name: `mlflow-artifacts-rmt` (remote);\n",
    "- AWS region: `eu-west-1`;\n",
    "- Everything else as default;\n",
    "- Create bucket\n",
    "\n",
    "**Note:** Check how much they are charging for it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6fd7b7",
   "metadata": {},
   "source": [
    "### 1.4. Create a postgresql DB - Location: `Ireland`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55aa28a5",
   "metadata": {},
   "source": [
    "- RDS service;\n",
    "- Create a Database (not a RDS Multi-AZ deployment);\n",
    "- Standard create;\n",
    "- Engine options: `PostgreSQL (13.4-R1)`\n",
    "- Templates: Free tier\n",
    "- DB instance identifier: `mlflow-db`\n",
    "- Master username: `mlflow_user`\n",
    "- Autogenerate a password;\n",
    "- Instance configuration: `db.t3.micro`\n",
    "- Port: `5432`\n",
    "\n",
    "\n",
    "Additional Configurations:\n",
    "- Initial db name: `mlflow_initial_db`;\n",
    "- Create Database\n",
    "\n",
    "Important details:\n",
    "- Save the password (only time you will see it)\n",
    "- Save the endpoint and port\n",
    "- Change the security group:\n",
    "    - Edit inbound rules\n",
    "    - Add a new rule to allow the `EC2 instance` to connect with the database;\n",
    "    - Postgresql - same security group than `EC2 instance`\n",
    "\n",
    "**Note:** No public access, because we only want the `EC2 instance`to reach this database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6cca76",
   "metadata": {},
   "source": [
    "### 1.5. Connect to `EC2 instance` - `Ireland`\n",
    "- Opens up a command line for the machine\n",
    "- Update the machine `sudo yum update`\n",
    "- Install required packages: `pip3 install mlflow boto3 psycopg2-binary` (to run mlflow, connect to aws, artifact store, and postgresql)\n",
    "- Configure aws account - `aws configure`:\n",
    "    - Use your own credentials - one can leave `region name`and `output format` unchanged\n",
    "- Check if there is any s3 bucket with: `aws s3 ls` - we are suppose to see the `s3 bucket`created;\n",
    "- Run the server:\n",
    "- `mlflow server -h 0.0.0.0 -p 5000 --backend-store-uri postgresql://DB_USER:DB_PASSWORD@DB_ENDPOINT:5432/DB_NAME --default-artifact-root s3://S3_BUCKET_NAME`\n",
    "- To access the tracking server, one just needs to go to `EC2 instance` and get the `public IPv4 DNS` and add the port, which is `5000` in our case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea194d0",
   "metadata": {},
   "source": [
    "### 1.6 Create a AWS configure file in your local computer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f17ae5f",
   "metadata": {},
   "source": [
    "- Follow [this](https://docs.aws.amazon.com/rekognition/latest/dg/setup-awscli-sdk.html) tutorial\n",
    "- How to create the files [here](https://docs.aws.amazon.com/rekognition/latest/dg/setup-awscli-sdk.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce2ae251",
   "metadata": {},
   "source": [
    "## 2. Access MLflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "273dcc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracking URL: http://ec2-18-212-215-30.compute-1.amazonaws.com:5000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import mlflow\n",
    "\n",
    "\n",
    "# Configuration variables\n",
    "os.environ[\"AWS_PROFILE\"] = \"ml-in-action\" # point to the profile create in your local computer\n",
    "\n",
    "TRACKING_SERVER_HOST = \"ec2-18-212-215-30.compute-1.amazonaws.com\" # this changes everytime we stop and restart and instance\n",
    "mlflow.set_tracking_uri(f\"http://{TRACKING_SERVER_HOST}:5000\")\n",
    "print(f\"tracking URL: {mlflow.get_tracking_uri()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83b2e41",
   "metadata": {},
   "source": [
    "## 3. Train the model and track it with mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78841b17",
   "metadata": {},
   "source": [
    "- If optimization is needed - [code](https://github.com/FDelca/mlops_datatalks_notes/blob/main/2-ExperimentTracking/Week2-LearningExercises.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9255e434",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='s3://mlflow-artifacts-rmt1/0', experiment_id='0', lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.list_experiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b569a9",
   "metadata": {},
   "source": [
    "### 3.1 Data Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea89468",
   "metadata": {},
   "source": [
    "- [data source](https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48c1513c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a data directory if it does not exist\n",
    "path = 'data'\n",
    "\n",
    "if not os.path.exists(path):\n",
    "    os.makedirs(path)\n",
    "\n",
    "for data_ in ['2021-01', '2021-02']:\n",
    "    data_path = f\"{path}/green_tripdata_{data_}.parquet\"\n",
    "    if not os.path.exists(data_path):\n",
    "        url = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/green_tripdata_{data_}.parquet\"\n",
    "        try:\n",
    "            os.system(f\"wget {url} -P \\data\")\n",
    "        except:\n",
    "            print(f\"{url} not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9175291",
   "metadata": {},
   "source": [
    "### 3.2 Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b100c795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "885b45b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel():\n",
    "    \n",
    "    def data_treatment(self, filename: str):\n",
    "        data = pd.read_parquet(filename)\n",
    "        data['duration'] = data.lpep_dropoff_datetime - data.lpep_pickup_datetime\n",
    "        data.duration = data.duration.dt.total_seconds() / 60\n",
    "        data = data[(data.duration >= 1) & (data.duration <= 60)]\n",
    "        \n",
    "        categorical = ['PULocationID', 'DOLocationID']\n",
    "        data[categorical] = data[categorical].astype(str)\n",
    "        return data\n",
    "        \n",
    "    def prepare_features(self, data: pd.DataFrame()):\n",
    "        data['PU_DO'] = data['PULocationID'] + '_' + data['DOLocationID']\n",
    "        categorical = ['PU_DO']\n",
    "        numerical = ['trip_distance']\n",
    "        dicts = data[categorical + numerical].to_dict(orient='records')\n",
    "        return dicts\n",
    "    \n",
    "    def fit(self, dict_train, y_train, dict_val, y_val):\n",
    "        \n",
    "        with mlflow.start_run():\n",
    "            params = dict(max_depth=20, n_estimators=100, min_samples_leaf=10, random_state=0)\n",
    "            mlflow.log_params(params)\n",
    "            \n",
    "            pipeline = make_pipeline(\n",
    "                DictVectorizer(),\n",
    "                RandomForestRegressor(**params, n_jobs=-1)\n",
    "            )\n",
    "            \n",
    "            pipeline.fit(dict_train, y_train)\n",
    "            \n",
    "            y_pred_train = pipeline.predict(dict_train)\n",
    "            y_pred_val = pipeline.predict(dict_val)\n",
    "            \n",
    "            rmse_train = mean_squared_error(y_pred_train, y_train, squared=False)\n",
    "            rmse_val = mean_squared_error(y_pred_val, y_val, squared=False)\n",
    "            \n",
    "            print(f\"Params: {params}\")\n",
    "            print(f\"rmse_train: {round(rmse_train, 2)}, rmse_val: {round(rmse_val, 2)}\")\n",
    "            \n",
    "            mlflow.log_metric('rmse_train', rmse_train)\n",
    "            mlflow.log_metric('rmse_val', rmse_val)\n",
    "            \n",
    "            mlflow.sklearn.log_model(pipeline, artifact_path=\"model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3834c23",
   "metadata": {},
   "source": [
    "### 3.3 Run to Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ac2cc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params: {'max_depth': 20, 'n_estimators': 100, 'min_samples_leaf': 10, 'random_state': 0}\n",
      "rmse_train: 5.75, rmse_val: 6.76\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fdelca/.virtualenvs/base/lib/python3.9/site-packages/_distutils_hack/__init__.py:33: UserWarning: Setuptools is replacing distutils.\n",
      "  warnings.warn(\"Setuptools is replacing distutils.\")\n"
     ]
    }
   ],
   "source": [
    "model_train = TrainModel()\n",
    "\n",
    "df_train = model_train.data_treatment('data/green_tripdata_2021-01.parquet')\n",
    "df_val = model_train.data_treatment('data/green_tripdata_2021-02.parquet')\n",
    "\n",
    "target = 'duration'\n",
    "y_train = df_train[target].values\n",
    "y_val = df_val[target].values\n",
    "\n",
    "dict_train = model_train.prepare_features(df_train)\n",
    "dict_val = model_train.prepare_features(df_val)\n",
    "\n",
    "model_train.fit(\n",
    "    dict_train=dict_train, \n",
    "    y_train=y_train, \n",
    "    dict_val=dict_val, \n",
    "    y_val=y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4e82fc",
   "metadata": {},
   "source": [
    "### 4. Load model from `s3 bucket` and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b138859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "# Configuration variables\n",
    "os.environ[\"AWS_PROFILE\"] = \"ml-in-action\"\n",
    "def load_model(run_id):\n",
    "    logged_model = f\"s3://mlflow-artifacts-rmt/0/{run_id}/artifacts/model\"\n",
    "    model = mlflow.pyfunc.load_model(logged_model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "459e7a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_ID = '8b4afe073de2423cad4b858170ac574f'\n",
    "model = load_model(run_id=RUN_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91331a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mlflow.pyfunc.loaded_model:\n",
       "  artifact_path: model\n",
       "  flavor: mlflow.sklearn\n",
       "  run_id: 8b4afe073de2423cad4b858170ac574f"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76382eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train = TrainModel()\n",
    "df_val = model_train.data_treatment('data/green_tripdata_2021-02.parquet')\n",
    "\n",
    "target = 'duration'\n",
    "y_val = df_val[target].values\n",
    "dict_val = model_train.prepare_features(df_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6aed10a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rmse_val: 6.76\n"
     ]
    }
   ],
   "source": [
    "y_pred_val = model.predict(dict_val)\n",
    "rmse_val = mean_squared_error(y_pred_val, y_val, squared=False)\n",
    "print(f\"rmse_val: {round(rmse_val, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d31a8e7",
   "metadata": {},
   "source": [
    "### Costs Saving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c2d3a6",
   "metadata": {},
   "source": [
    "After the end of this tutorial to only keep the model one can stop any other resource except the `s3 bucket` that actually holds the project online."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
